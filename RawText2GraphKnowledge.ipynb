{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFDvPiqFiUJX",
        "outputId": "56b1b981-6d41-4c7c-e544-3c214b047857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import gensim\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "-1FUZh9PiX9E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5A4zRG_imXw",
        "outputId": "8b54cb22-21d9-400c-a5ba-99395aaf1885"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Tasks\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    tokens = word_tokenize(text) # Tokenization\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [token for token in tokens if token not in stop_words] # Stopword Removal\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens] # Lemmatization\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "QIMc9sKeiqCF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read file and preprocess functions\n",
        "def read_and_preprocess_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return preprocess_text(text)\n",
        ""
      ],
      "metadata": {
        "id": "oKB-lznKjJWh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec procedure\n",
        "def train_word2vec_model(preprocessed_text, vector_size=100, window=5, min_count=1, workers=4):\n",
        "    model = gensim.models.Word2Vec(\n",
        "        [preprocessed_text],\n",
        "        vector_size=vector_size,\n",
        "        window=window,\n",
        "        min_count=min_count,\n",
        "        workers=workers\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "sR1Vy_FDjSkR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coocurrence Based Graph constructor\n",
        "def create_coocurrence_graph(preprocessed_text, window_size=2):\n",
        "    graph = nx.Graph()\n",
        "    word_count = defaultdict(int)\n",
        "\n",
        "    for i, word in enumerate(preprocessed_text):\n",
        "        word_count[word] += 1\n",
        "\n",
        "        for j in range(max(0, i-window_size), min(len(preprocessed_text), i+window_size+1)):\n",
        "            if i != j:\n",
        "                if not graph.has_edge(preprocessed_text[i], preprocessed_text[j]):\n",
        "                    graph.add_edge(preprocessed_text[i], preprocessed_text[j], weight=1)\n",
        "                else:\n",
        "                    graph[preprocessed_text[i]][preprocessed_text[j]]['weight'] += 1\n",
        "    return graph\n"
      ],
      "metadata": {
        "id": "tpvZA0d7jrem"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec Based Graph Constructor\n",
        "def create_word2vec_graph(model, top_n=10):\n",
        "    graph = nx.Graph()\n",
        "    vocab = model.wv.key_to_index\n",
        "\n",
        "    for word in vocab:\n",
        "        similar_words = model.wv.most_similar(word, topn=top_n)\n",
        "        for similar_word, similarity in similar_words:\n",
        "            graph.add_edge(word, similar_word, weight=similarity)\n",
        "    return graph"
      ],
      "metadata": {
        "id": "EuE4_pDrklYk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph visualization function\n",
        "def visualize_graph(graph, title=\"Knowledge Graph\"):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    pos = nx.spring_layout(graph, k=0.5)\n",
        "    nx.draw(graph, pos, with_labels=True, node_size=1500, node_color='skyblue', font_size=10, font_color='black', font_weight='bold', width=1.2)\n",
        "    edge_labels = nx.get_edge_attributes(graph, 'weight')\n",
        "    nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_size=8)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tShYE799nPfK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save graph to the file\n",
        "def save_graph_to_file(graph, filename):\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        for u, v, data in graph.edges(data=True):\n",
        "            weight = data.get('weight', 1)\n",
        "            f.write(f\"{u}, {v}, {weight}\\n\")\n",
        "    print(\"Sucess write the graph\")"
      ],
      "metadata": {
        "id": "yM6eaPHrnwjN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/BigRock.txt\""
      ],
      "metadata": {
        "id": "2QpBQ43moSy4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_text = read_and_preprocess_text(file_path)"
      ],
      "metadata": {
        "id": "F-9KmqLjoc_T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the word to vector\n",
        "word2vec_model = train_word2vec_model(preprocessed_text)"
      ],
      "metadata": {
        "id": "c67MzbawogcD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faGVKet9o5C9",
        "outputId": "528ddb4c-005a-4b3c-e5f9-cfcf95412c4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x780e2fcc6210>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coocurrence_graph = create_coocurrence_graph(preprocessed_text)"
      ],
      "metadata": {
        "id": "JqJ2FBmnpGw6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coocurrence_graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnlcnwmTpMcP",
        "outputId": "9d7e4256-c300-4eb6-a98b-e5cbc9c851e3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x780e2fd6d8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_graph = create_word2vec_graph(word2vec_model)"
      ],
      "metadata": {
        "id": "zeXFMdd6pbis"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_graph_to_file(coocurrence_graph, \"coocurrence_graph.txt\")\n",
        "save_graph_to_file(similarity_graph, \"similarity_graph.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgu7pJh8pRGm",
        "outputId": "a73ac661-f6ac-460b-b589-0e4a87677f5a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucess write the graph\n",
            "Sucess write the graph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_graph(coocurrence_graph, \"Coocurrence Graph\")"
      ],
      "metadata": {
        "id": "f7OdECvWp1nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_graph(similarity_graph, \"Word2Vec Graph\")"
      ],
      "metadata": {
        "id": "hsB7OjuaqINr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZO11Np5qJ5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}